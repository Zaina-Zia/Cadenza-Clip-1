{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13670539,"sourceType":"datasetVersion","datasetId":8692267}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"# Paths and hyperparameters\nUNPROCESSED_DIR = \"/kaggle/input/cadenza/cadenza_clip1_data.train.v1.0/cadenza_data/train/unprocessed\"\nPROCESSED_DIR = \"/kaggle/input/cadenza/cadenza_clip1_data.train.v1.0/cadenza_data/train/signals\"\nMETADATA_FILE = \"/kaggle/input/cadenza/cadenza_clip1_data.train.v1.0/cadenza_data/metadata/train_metadata.json\"\nOUTPUT_DIR = \"/kaggle/working/output\"\n\nWAV2VEC_MODEL = \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\"\n\nMAX_AUDIO_LEN = 16000 * 10   # 15 sec max\nBATCH_SIZE = 32\nLR = 1e-4\nEPOCHS = 5\nVAL_SPLIT = 0.2\n\nDEVICE = \"cuda\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:29:46.543045Z","iopub.execute_input":"2025-11-14T18:29:46.543642Z","iopub.status.idle":"2025-11-14T18:29:46.547659Z","shell.execute_reply.started":"2025-11-14T18:29:46.543614Z","shell.execute_reply":"2025-11-14T18:29:46.546893Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport torchaudio\nfrom torch.utils.data import Dataset\n\nclass CadenzaDataset(Dataset):\n    def __init__(self, meta_file, clean_dir, processed_dir, max_len):\n        with open(meta_file, \"r\") as f:\n            self.records = json.load(f)\n        self.clean_dir = clean_dir\n        self.processed_dir = processed_dir\n        self.max_len = max_len\n\n    def _load_audio(self, path):\n        wav, sr = torchaudio.load(path)\n        wav = wav.mean(dim=0)  # mono\n        # pad or crop\n        if wav.shape[0] > self.max_len:\n            wav = wav[:self.max_len]\n        else:\n            wav = torch.nn.functional.pad(wav, (0, self.max_len - wav.shape[0]))\n        return wav\n\n    def __getitem__(self, idx):\n        r = self.records[idx]\n        signal = r[\"signal\"]\n        correctness = torch.tensor(r[\"correctness\"], dtype=torch.float32)\n\n        # unprocessed file has _unproc.flac\n        unproc_path = os.path.join(self.clean_dir, f\"{signal}_unproc.flac\")\n        clean = self._load_audio(unproc_path)\n\n        # processed file has just signal.flac\n        proc_path = os.path.join(self.processed_dir, f\"{signal}.flac\")\n        processed = self._load_audio(proc_path)\n\n        return {\n            \"signal\": signal,\n            \"clean\": clean,\n            \"processed\": processed,\n            \"correctness\": correctness,\n        }\n\n\n    def __len__(self):\n        return len(self.records)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:29:46.548599Z","iopub.execute_input":"2025-11-14T18:29:46.548798Z","iopub.status.idle":"2025-11-14T18:29:46.567724Z","shell.execute_reply.started":"2025-11-14T18:29:46.548783Z","shell.execute_reply":"2025-11-14T18:29:46.567125Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import Wav2Vec2Model\n\nclass SiameseWav2Vec2(nn.Module):\n    def __init__(self, model_name):\n        super().__init__()\n        self.encoder = Wav2Vec2Model.from_pretrained(model_name)\n        hidden = self.encoder.config.hidden_size\n        self.reg_head = nn.Sequential(\n            nn.Linear(hidden, 256),\n            nn.ReLU(),\n            nn.Linear(256, 1),\n            nn.Sigmoid()  # output 0–1 intelligibility\n        )\n\n    def encode(self, wav):\n        out = self.encoder(wav).last_hidden_state\n        pooled = out.mean(dim=1)\n        return pooled\n\n    def forward(self, clean, processed):\n        c = self.encode(clean)\n        p = self.encode(processed)\n        diff = torch.abs(c - p)\n        pred = self.reg_head(diff)\n        return pred.squeeze(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:29:46.568656Z","iopub.execute_input":"2025-11-14T18:29:46.568846Z","iopub.status.idle":"2025-11-14T18:29:46.587867Z","shell.execute_reply.started":"2025-11-14T18:29:46.568831Z","shell.execute_reply":"2025-11-14T18:29:46.587260Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nfrom torch.utils.data import DataLoader, random_split, Subset\nfrom tqdm import tqdm\nimport torch\n\n# Split dataset into 80% train / 20% eval\ndataset = CadenzaDataset(METADATA_FILE, UNPROCESSED_DIR, PROCESSED_DIR, MAX_AUDIO_LEN)\ntotal_samples = len(dataset)\nindices = list(range(total_samples))\nrandom.shuffle(indices)\n\ntrain_cutoff = int(0.8 * total_samples)\ntrain_indices = indices[:train_cutoff]\neval_indices  = indices[train_cutoff:]\n\ntrain_ds = Subset(dataset, train_indices)\neval_ds  = Subset(dataset, eval_indices)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\neval_loader  = DataLoader(eval_ds, batch_size=BATCH_SIZE, shuffle=False)\n\n# Model\nmodel = SiameseWav2Vec2(WAV2VEC_MODEL).to(DEVICE)\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR)\ncriterion = torch.nn.MSELoss()\n\n# Training loop\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    model.train()\n    for batch in tqdm(train_loader, desc=\"Training\"):\n        clean = batch[\"clean\"].to(DEVICE)\n        processed = batch[\"processed\"].to(DEVICE)\n        y = batch[\"correctness\"].to(DEVICE)\n\n        optimizer.zero_grad()\n        preds = model(clean, processed)\n        loss = criterion(preds, y)\n        loss.backward()\n        optimizer.step()\n\n# Save trained model\nos.makedirs(OUTPUT_DIR, exist_ok=True)\ntorch.save(model.state_dict(), f\"{OUTPUT_DIR}/siamese_wav2vec2.pt\")\nprint(\"Model saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:29:46.588761Z","iopub.execute_input":"2025-11-14T18:29:46.589066Z","iopub.status.idle":"2025-11-14T19:14:49.829301Z","shell.execute_reply.started":"2025-11-14T18:29:46.589050Z","shell.execute_reply":"2025-11-14T19:14:49.828548Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 221/221 [10:07<00:00,  2.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 221/221 [08:44<00:00,  2.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 221/221 [08:41<00:00,  2.36s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 221/221 [08:43<00:00,  2.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 221/221 [08:46<00:00,  2.38s/it]","output_type":"stream"},{"name":"stdout","text":"Model saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"import csv\n\n# Load trained model\nmodel = SiameseWav2Vec2(WAV2VEC_MODEL).to(DEVICE)\nmodel.load_state_dict(torch.load(f\"{OUTPUT_DIR}/siamese_wav2vec2.pt\"))\nmodel.eval()\n\npred_file = f\"{OUTPUT_DIR}/predictions.csv\"\nwith open(pred_file, \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    with torch.no_grad():\n        for batch in tqdm(eval_loader, desc=\"Predicting\"):\n            clean = batch[\"clean\"].to(DEVICE)\n            processed = batch[\"processed\"].to(DEVICE)\n            preds = model(clean, processed).cpu().numpy()\n            for signal, p in zip(batch[\"signal\"], preds):\n                writer.writerow([signal, float(p)])\n\nprint(\"Predictions saved:\", pred_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:14:49.830836Z","iopub.execute_input":"2025-11-14T19:14:49.831134Z","iopub.status.idle":"2025-11-14T19:15:54.121685Z","shell.execute_reply.started":"2025-11-14T19:14:49.831110Z","shell.execute_reply":"2025-11-14T19:15:54.120908Z"}},"outputs":[{"name":"stderr","text":"Predicting: 100%|██████████| 56/56 [01:03<00:00,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Predictions saved: /kaggle/working/output/predictions.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom scipy.stats import kendalltau, pearsonr\nimport numpy as np\n\ndef rmse(a, b):\n    return np.sqrt(np.mean((a - b) ** 2))\n\ndef stderr(a, b):\n    return np.std(a - b) / np.sqrt(len(a))\n\ndef ncc(a, b):\n    return pearsonr(a, b)[0]\n\ndef kt(a, b):\n    return kendalltau(a, b)[0]\n\n# Load metadata\nwith open(METADATA_FILE, \"r\") as f:\n    rec = json.load(f)\ngt = {r[\"signal\"]: r[\"correctness\"] for r in rec}\n\n# Load predictions\ndf = pd.read_csv(f\"{OUTPUT_DIR}/predictions.csv\", names=[\"signal\",\"pred\"])\ny_true = np.array([gt[s] for s in df.signal])\ny_pred = df.pred.values\n\nscores = {\n    \"RMSE\": rmse(y_pred, y_true),\n    \"Std\": stderr(y_pred, y_true),\n    \"NCC\": ncc(y_pred, y_true),\n    \"KT\": kt(y_pred, y_true),\n}\n\nprint(json.dumps(scores, indent=2))\n\nwith open(f\"{OUTPUT_DIR}/evaluation.json\", \"w\") as f:\n    json.dump(scores, f, indent=2)\n\nprint(\"Evaluation saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:15:54.136416Z","iopub.execute_input":"2025-11-14T19:15:54.136647Z","iopub.status.idle":"2025-11-14T19:15:54.181900Z","shell.execute_reply.started":"2025-11-14T19:15:54.136623Z","shell.execute_reply":"2025-11-14T19:15:54.181343Z"}},"outputs":[{"name":"stdout","text":"{\n  \"RMSE\": 0.3369441922418843,\n  \"Std\": 0.008028022958211305,\n  \"NCC\": 0.32272109534203897,\n  \"KT\": 0.23866481732366823\n}\nEvaluation saved.\n","output_type":"stream"}],"execution_count":20}]}